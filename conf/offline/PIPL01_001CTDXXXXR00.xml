<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE instrument SYSTEM "../instrument.dtd">
<instrument>
    <!-- the instrument short name -->
    <shortName>NS08</shortName>
    <!-- The instrument identifier -->
    <identifier>PIPL01_001CTDXXXXR00</identifier>
    <!-- The connection type: socket, file, or serial -->
    <connectionType>file</connectionType>
    <!-- 
      Configure connection parameters based on connection type. If connection
      type is socket, add hostName and hostPort below. If file, add filePath
      below. If serial, add serialPortParams and sub elements below.
    -->
    <connectionParams>
        <filePath>/home/kilonalu/PIPL01_001CTDXXXXR00_latest_data.txt</filePath>
    </connectionParams>
    <!-- The name of the instrument source as it appears in the DataTurbine -->
    <rbnbName>PIPL01_001CTDXXXXR00</rbnbName>
    <!-- The IP or host name of the DataTurbine server -->
    <rbnbServer>realtime.pacioos.hawaii.edu</rbnbServer>
    <!-- The port number of the DataTurbine server -->
    <rbnbPort>3333</rbnbPort>
    <!-- The number of in-memory bytes to request for this instrument source -->
    <archiveMemory>50000</archiveMemory>
    <!-- The number of on-disk bytes to request for this instrument source -->
    <archiveSize>31536000</archiveSize>
    <!-- The list of data channels to be created in the DataTurbine for this instrument source -->
    <channels>
        <!-- The default channel details. This will push ASCII data into the DataTurbine -->
        <channel default="true">
            <!-- The name of the channel -->
            <name>DecimalASCIISampleData</name>
            <!-- The channel's incoming data type -->
            <dataType>String</dataType>
            <!-- data archive example:
            # 30.5786,  5.74856,    3.260, 0.0700, 0.2133,  34.0035, 24 May 2010 12:55:56
            # 30.5713,  5.74978,    3.281, 0.0698, 0.2097,  34.0168, 24 May 2010 12:59:56
            # 30.5578,  5.74981,    3.297, 0.0713, 0.2173,  34.0264, 24 May 2010 13:03:56
            # 30.5421,  5.75005,    3.313, 0.0723, 0.2162,  34.0389, 24 May 2010 13:07:56
            # 30.5417,  5.75029,    3.331, 0.0733, 0.2238,  34.0408, 24 May 2010 13:11:56
            # 30.5397,  5.75093,    3.351, 0.0752, 0.2041,  34.0464, 24 May 2010 13:15:56
            # 30.5358,  5.75116,    3.370, 0.0719, 0.2154,  34.0506, 24 May 2010 13:19:56
            # 30.5395,  5.75109,    3.389, 0.0686, 0.2098,  34.0476, 24 May 2010 13:23:56
            # 30.5333,  5.75196,    3.408, 0.0674, 0.2060,  34.0578, 24 May 2010 13:27:56
            # 30.5208,  5.75166,    3.425, 0.0770, 0.2321,  34.0645, 24 May 2010 13:31:56
            # 30.5205,  5.75170,    3.445, 0.0748, 0.2290,  34.0650, 24 May 2010 13:35:56
            # 30.5140,  5.75138,    3.465, 0.0745, 0.2232,  34.0673, 24 May 2010 13:39:56
            -->
            <!-- 
              The regular expression used to match a data sample.
              Best to keep the data pattern on one line below 
            -->
            <dataPattern>#\s+\S+,\s+\S+,\s+\S+,\s+\S+,\s+\S+,\s+\S+,\s+\d{2}\s+\S{3}\s+\d{4}\s+\d{2}:\d{2}:\d{2}\s*</dataPattern>
            <!--
                dataPrefix: A string of characters that prefix the data in a sample (e.g. '#')
            -->
            <dataPrefix>#</dataPrefix>
            <!--
                columnTypes: A list of column types for each variable in the sample. Use STRING
                for all column types except:
                - date-only columns: use LOCAL_DATE
                - time-only columns: use LOCAL_TIME
                - date-time columns: use LOCAL_DATE_TIME
            -->
            <columnTypes>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>LOCAL_DATE_TIME</columnType>
            </columnTypes>
            <!--
              The character that delimits variables within the sample
              Use Hex notation for non-printing, whitespace characters (like space)
            -->
            <fieldDelimiter>,</fieldDelimiter>
            <!-- 
              The character(s) that delimit records (samples) in a stream or file
              Use Hex notation for non-printing characters, separate characters with a pipe
            -->
            <recordDelimiters>0x0D|0x0A</recordDelimiters>
            <!-- 
              The list of date formats for each sample date component in a separate variable
              One or more date formats are required, reflecting the date/time variables in the data
              Note: dateFormat and dateField are used together to locate, then parse the sample date
              -->
            <dateFormats>
                <dateFormat>dd MMM yyyy HH:mm:ss</dateFormat> 
            </dateFormats>
            <!-- 
              The list of date fields for each sample date component in a separate variable
              One or more date fields are required, corresponding to the date/time variable positions in the data 
            -->        
            <dateFields>
                <dateField>7</dateField>
            </dateFields>
            <!--
              timeZone: The time zone identifier that the data were collected in (e.g. Pacific/Honolulu).
              The parsers are strict about zone identifiers, and will fall back to UTC when the
              now-deprecated zone names are used (in the format of HDT, HST, SST, etc.). They are
              considered ambiguous due to conflicting global use.  Only use identifiers that follow
              the <region>/<locality> pattern (like Pacific/Samoa). While an exact offset like
              GMT+13:00 will also work, it may change over time due to daylight savings,
              so the long identifier is best.
            -->
            <timeZone>Pacific/Palau</timeZone>
            <!-- The list of data archivers used to write data to disk -->
            <archivers>
                <!-- Write the raw data to /data/raw -->
                <archiver>
                    <archiveType>raw</archiveType>
                    <archiveInterval>hourly</archiveInterval>
                    <archiveBaseDirectory>/data/raw/pacioos</archiveBaseDirectory>
                </archiver>
                <!-- Write the PacIOOS 2020 formatted data to /data/processed -->
                <archiver>
                    <archiveType>pacioos-2020-format</archiveType>
                    <archiveInterval>daily</archiveInterval>
                    <archiveBaseDirectory>/data/processed/pacioos</archiveBaseDirectory>
                </archiver>
            </archivers>
        </channel>
    </channels>
</instrument>
