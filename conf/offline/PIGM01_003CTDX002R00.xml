<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE instrument SYSTEM "../instrument.dtd">
<instrument>
    <!-- the instrument short name -->
    <shortName>NS17</shortName>
    <!-- The instrument identifier -->
    <identifier>PIGM01_003CTDX002R00</identifier>
    <!-- The connection type: socket, file, or serial -->
    <connectionType>file</connectionType>
    <!-- 
      Configure connection parameters based on connection type. If connection
      type is socket, add hostName and hostPort below. If file, add filePath
      below. If serial, add serialPortParams and sub elements below.
    -->
    <connectionParams>
        <filePath>/home/kilonalu/PIGM01_003CTDX002R00_latest_data.txt</filePath>
    </connectionParams>
    <!-- The name of the instrument source as it appears in the DataTurbine -->
    <rbnbName>PIGM01_003CTDX002R00</rbnbName>
    <!-- The IP or host name of the DataTurbine server -->
    <rbnbServer>realtime.pacioos.hawaii.edu</rbnbServer>
    <!-- The port number of the DataTurbine server -->
    <rbnbPort>3333</rbnbPort>
    <!-- The number of in-memory bytes to request for this instrument source -->
    <archiveMemory>50000</archiveMemory>
    <!-- The number of on-disk bytes to request for this instrument source -->
    <archiveSize>31536000</archiveSize>
    <!-- The list of data channels to be created in the DataTurbine for this instrument source -->
    <channels>
        <!-- The default channel details. This will push ASCII data into the DataTurbine -->
        <channel default="true">
            <!-- The name of the channel -->
            <name>DecimalASCIISampleData</name>
            <!-- The channel's incoming data type -->
            <dataType>String</dataType>
            <!-- data archive example:
            # -999.0,  5.041538,  0.918,  0.0900,  0.7012,  -999.0,  26 Nov 2019 02:01:08
            # -999.0,  5.279137,  1.078,  0.0879,  0.5017,  -999.0,  26 Nov 2019 03:01:08
            # -999.0,  5.444123,  1.251,  0.0845,  0.4182,  -999.0,  26 Nov 2019 04:01:08
            # -999.0,  5.499211,  1.421,  0.0829,  0.3996,  -999.0,  26 Nov 2019 05:01:08
            # -999.0,  5.514008,  1.559,  0.0833,  0.4776,  -999.0,  26 Nov 2019 06:01:08
            # -999.0,  5.500043,  1.593,  0.0902,  0.5566,  -999.0,  26 Nov 2019 07:01:08
            # -999.0,  5.485395,  1.604,  0.0940,  0.6014,  -999.0,  26 Nov 2019 08:01:08
            # -999.0,  5.515142,  1.560,  0.0858,  0.5338,  -999.0,  26 Nov 2019 09:01:08
            # -999.0,  5.554703,  1.552,  0.0877,  0.6292,  -999.0,  26 Nov 2019 10:01:08
            # -999.0,  5.574447,  1.527,  0.0845,  0.8465,  -999.0,  26 Nov 2019 11:01:08
            # -999.0,  5.593059,  1.503,  0.0914,  0.6474,  -999.0,  26 Nov 2019 12:01:08
            # -999.0,  5.567352,  1.447,  0.0844,  0.6027,  -999.0,  26 Nov 2019 13:01:08
            # -999.0,  5.601036,  1.421,  0.0912,  0.7820,  -999.0,  26 Nov 2019 14:01:08
            -->
            <!-- 
              The regular expression used to match a data sample.
              Best to keep the data pattern on one line below 
            -->
            <dataPattern># *\S*, *\S*, *\S*, *\S*, *\S*, *\S*, *\d{2} \S{3} \d{4} *\d{2}:\d{2}:\d{2}\s*</dataPattern>
            <!--
                dataPrefix: A string of characters that prefix the data in a sample (e.g. '#')
            -->
            <dataPrefix>#</dataPrefix>
            <!--
                columnTypes: A list of column types for each variable in the sample. Use STRING
                for all column types except:
                - date-only columns: use LOCAL_DATE
                - time-only columns: use LOCAL_TIME
                - date-time columns: use LOCAL_DATE_TIME
            -->
            <columnTypes>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>LOCAL_DATE_TIME</columnType>
            </columnTypes>
            <!--
              The character that delimits variables within the sample
              Use Hex notation for non-printing, whitespace characters (like space)
            -->
            <fieldDelimiter>,</fieldDelimiter>
            <!-- 
              The character(s) that delimit records (samples) in a stream or file
              Use Hex notation for non-printing characters, separate characters with a pipe
            -->
            <recordDelimiters>0x0D|0x0A</recordDelimiters>
            <!-- 
              The list of date formats for each sample date component in a separate variable
              One or more date formats are required, reflecting the date/time variables in the data
              Note: dateFormat and dateField are used together to locate, then parse the sample date
              -->
            <dateFormats>
                <dateFormat>dd MMM yyyy HH:mm:ss</dateFormat> 
            </dateFormats>
            <!-- 
              The list of date fields for each sample date component in a separate variable
              One or more date fields are required, corresponding to the date/time variable positions in the data 
            -->        
            <dateFields>
                <dateField>7</dateField>
            </dateFields>
            <!--
              timeZone: The time zone identifier that the data were collected in (e.g. Pacific/Honolulu).
              The parsers are strict about zone identifiers, and will fall back to UTC when the
              now-deprecated zone names are used (in the format of HDT, HST, SST, etc.). They are
              considered ambiguous due to conflicting global use.  Only use identifiers that follow
              the <region>/<locality> pattern (like Pacific/Samoa). While an exact offset like
              GMT+13:00 will also work, it may change over time due to daylight savings,
              so the long identifier is best.
            -->
            <timeZone>Pacific/Guam</timeZone>
            <!-- The list of data archivers used to write data to disk -->
            <archivers>
                <!-- Write the raw data to /data/raw -->
                <archiver>
                    <archiveType>raw</archiveType>
                    <archiveInterval>hourly</archiveInterval>
                    <archiveBaseDirectory>/data/raw/pacioos</archiveBaseDirectory>
                </archiver>
                <!-- Write the PacIOOS 2020 formatted data to /data/processed -->
                <archiver>
                    <archiveType>pacioos-2020-format</archiveType>
                    <archiveInterval>daily</archiveInterval>
                    <archiveBaseDirectory>/data/processed/pacioos</archiveBaseDirectory>
                </archiver>
            </archivers>
        </channel>
    </channels>
</instrument>
