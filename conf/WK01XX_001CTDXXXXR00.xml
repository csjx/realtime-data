<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE instrument SYSTEM "instrument.dtd">
<instrument>
    <!-- The instrument identifier -->
    <identifier>WK01XX_001CTDXXXXR00</identifier>
    <!-- The connection type: socket, file, or serial -->
    <connectionType>file</connectionType>
    <!-- 
      Configure connection parameters based on connection type. If connection
      type is socket, add hostName and hostPort below. If file, add filePath
      below. If serial, add serialPortParams and sub elements below.
    -->
    <connectionParams>
        <hostName>68.25.168.134</hostName>
        <hostPort>5113</hostPort>
    </connectionParams>
    <!-- The name of the instrument source as it appears in the DataTurbine -->
    <rbnbName>WK01XX_001CTDXXXXR00</rbnbName>
    <!-- The IP or host name of the DataTurbine server -->
    <rbnbServer>realtime.pacioos.hawaii.edu</rbnbServer>
    <!-- The port number of the DataTurbine server -->
    <rbnbPort>3333</rbnbPort>
    <!-- The number of in-memory bytes to request for this instrument source -->
    <archiveMemory>50000</archiveMemory>
    <!-- The number of on-disk bytes to request for this instrument source -->
    <archiveSize>31536000</archiveSize>
    <!-- The list of data channels to be created in the DataTurbine for this instrument source -->
    <channels>
        <!-- The default channel details. This will push ASCII data into the DataTurbine -->
        <channel default="true">
            <!-- The name of the channel -->
            <name>DecimalASCIISampleData</name>
            <!-- The channel's incoming data type -->
            <dataType>String</dataType>
            <!-- data archive example:
            #  24.6643,  5.25949,    0.929,  34.9057, 22 Dec 2016, 03:03:06
            #  24.6532,  5.25841,    0.897,  34.9064, 22 Dec 2016, 03:07:06
            #  24.6474,  5.25773,    1.016,  34.9057, 22 Dec 2016, 03:11:06
            #  24.6367,  5.25654,    0.926,  34.9052, 22 Dec 2016, 03:15:06
            #  24.6322,  5.25609,    0.951,  34.9053, 22 Dec 2016, 03:19:06
            #  24.6364,  5.25627,    0.855,  34.9034, 22 Dec 2016, 03:23:06
            #  24.6331,  5.25602,    0.929,  34.9041, 22 Dec 2016, 03:27:06
            #  24.6277,  5.25550,    0.875,  34.9044, 22 Dec 2016, 03:31:06
            #  24.6217,  5.25497,    0.869,  34.9052, 22 Dec 2016, 03:35:06
            #  24.6268,  5.25533,    0.863,  34.9039, 22 Dec 2016, 03:39:06
            -->
            <!-- example DT sample:
            curl -s -o - http://realtime.pacioos.hawaii.edu:8080/RBNB/WK01XX_001CTDXXXXR00/DecimalASCIISampleData | od -ax
            0000000   #  sp  sp   2   4   .   5   1   3   0   ,  sp  sp   5   .   2
                    2023 3220 2e34 3135 3033 202c 3520 322e
            0000020   4   1   3   6   ,  sp  sp  sp  sp   0   .   9   2   0   ,  sp
                    3134 3633 202c 2020 3020 392e 3032 202c
            0000040  sp   3   4   .   8   8   7   8   ,  sp   2   2  sp   D   e   c
                    3320 2e34 3838 3837 202c 3232 4420 6365
            0000060  sp   2   0   1   6   ,  sp   0   9   :   5   1   :   0   6  cr
                    3220 3130 2c36 3020 3a39 3135 303a 0d36
            0000100  nl nul
                    000a
            0000101
            -->
            <!-- 
              The regular expression used to match a data sample.
              Best to keep the data pattern on one line below 
            -->
            <dataPattern># *\S*, *\S*, *\S*, *\S*, *\d{2} \S{3} \d{4}, *\d{2}:\d{2}:\d{2}\s*</dataPattern>
            <!--
                dataPrefix: A string of characters that prefix the data in a sample (e.g. '#')
            -->
            <dataPrefix>#</dataPrefix>

            <!--
                columnTypes: A list of column types for each variable in the sample. Use STRING
                for all column types except:
                - date-only columns: use LOCAL_DATE
                - time-only columns: use LOCAL_TIME
                - date-time columns: use LOCAL_DATE_TIME
            -->
            <columnTypes>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>STRING</columnType>
                <columnType>LOCAL_DATE</columnType>
                <columnType>LOCAL_TIME</columnType>
            </columnTypes>
            <!--
              The character that delimits variables within the sample
              Use Hex notation for non-printing, whitespace characters (like space)
            -->
            <fieldDelimiter>,</fieldDelimiter>
            <!-- 
              The character(s) that delimit records (samples) in a stream or file
              Use Hex notation for non-printing characters, separate characters with a pipe
            -->
            <recordDelimiters>0x0D|0x0A</recordDelimiters>
            <!--
              missingValueCode: A code indicating that a value is missing in the sample (NaN, -999, etc.)
            -->
            <missingValueCode>-999</missingValueCode>
            <!-- 
              The list of date formats for each sample date component in a separate variable
              One or more date formats are required, reflecting the date/time variables in the data
              Note: dateFormat and dateField are used together to locate, then parse the sample date
              -->
            <dateFormats>
                <dateFormat>dd MMM yyyy</dateFormat> 
                <dateFormat>HH:mm:ss</dateFormat> 
            </dateFormats>
            <!-- 
              The list of date fields for each sample date component in a separate variable
              One or more date fields are required, corresponding to the date/time variable positions in the data 
            -->        
            <dateFields>
                <dateField>5</dateField>
                <dateField>6</dateField>
            </dateFields>
            <!--
              timeZone: The time zone identifier that the data were collected in (e.g. Pacific/Honolulu).
              The parsers are strict about zone identifiers, and will fall back to UTC when the
              now-deprecated zone names are used (in the format of HDT, HST, SST, etc.). They are
              considered ambiguous due to conflicting global use.  Only use identifiers that follow
              the <region>/<locality> pattern (like Pacific/Samoa). While an exact offset like
              GMT+13:00 will also work, it may change over time due to daylight savings,
              so the long identifier is best.
            -->
            <timeZone>Pacific/Honolulu</timeZone>
            <!-- The list of data archivers used to write data to disk -->
            <archivers>
                <!-- Write the raw data to /data/raw -->
                <archiver>
                    <archiveType>raw</archiveType>
                    <archiveInterval>hourly</archiveInterval>
                    <archiveBaseDirectory>/Users/cjones/data/raw/alawai</archiveBaseDirectory>
                </archiver>
                <!-- Write the PacIOOS 2020 formatted data to /data/processed -->
                <archiver>
                    <archiveType>pacioos-2020-format</archiveType>
                    <archiveInterval>daily</archiveInterval>
                    <archiveBaseDirectory>/data/processed/pacioos</archiveBaseDirectory>
                </archiver>
            </archivers>
        </channel>
    </channels>
</instrument>